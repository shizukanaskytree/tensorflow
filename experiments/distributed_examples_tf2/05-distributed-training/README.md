Distributed training allows scaling up deep learning task so bigger models can be learned or training can be conducted at a faster pace. In a previous tutorial, we discussed how to use ```MirroredStrategy``` to achieve multi-GPU training within a single node (physical machine). In this tutorial, we will explain how to do distributed training across multiple nodes. This tutorial includes:

* Code boilerplate for multi-node distributed training.
* Example code runs multiple machines.

To reproduce this tutorial, please refer to this [distributed training with TensorFlow 2 github repository](https://github.com/lambdal/TensorFlow2-tutorial/tree/master/05-distributed-training).


# Another official tutorial

https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras

## Code Boilerplate

Similar to multi-GPU training within a single node, multi-node training also uses a distributed strategy. In this case, ```tf.distribute.experimental.MultiWorkerMirroredStrategy```. Multi-node training further requires a ```TF_CONFIG``` environment variable to be set. Note that the environment variable will be slightly different on each node. For example, this is the setting on ```worker 0``` in a two-node distributed training job: 

```
os.environ["TF_CONFIG"] = json.dumps({
    'cluster': {
        'worker': ["10.1.10.58:12345", "10.1.10.250:12345"]
    },
    'task': {'type': 'worker', 'index': 0}
})
```


Essentially, TF_CONFIG is a JSON string that represents the cluster and identifies this machine's role in that cluster. The code above sets the TF_CONFIG environment variable which can also be set using a command line export or as a prefix on your shell command for example:

```export TF_CONFIG='{"cluster": {"worker": ["10.1.10.58:12345", "10.1.10.250:12345"]}, "task": {"index": 0, "type": "worker"}}'
```

or

```
TF_CONFIG='{"cluster": {"worker": ["10.1.10.58:12345", "10.1.10.250:12345"]}, "task": {"index": 0, "type": "worker"}}' python worker.py
```

The ```cluster``` field is the same across all nodes. It describes how the cluster is set up. In this case, our cluster only has two worker nodes, whose ```IP:port``` information is listed in the ```worker``` array. The ```task``` field varies from node to node. It specifies the type and index of the node, which is then used to fetch details from the ```cluster``` field and given to the task manager to divvy up the work. In this case, this config file indicates the training job runs on worker 0, which is ```"10.1.10.58:12345"```

We need to customize this python snippet for each node. So the second node will have ```'task': {'type': 'worker', 'index': 1}```. 

We then need to create the distributed strategy:

```
strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
```

Notice this line has to be done after the definition of ```TF_CONFIG``` and before the definition of data pipeline and model. Otherwise, a ```Collective ops must be configured at program startup``` error will be triggered. 

Last bit of the code boilplate defines the model under the strategy scope:

```
with strategy.scope():
  model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)
  model.compile(
            optimizer=opt,
            loss='sparse_categorical_crossentropy',
            metrics=['sparse_categorical_accuracy']) 
model.fit(train_dataset,
          epochs=NUM_EPOCHS)
```

## Run the training

To run distributed training, the training script needs to be customized and copied to all nodes. To make it clearer, we can set the environment variable using the prefix syntax. This is set differently on each node.

Make sure the nodes can ssh into each other without the request of the password. The most convenient way to do this is to use ssh keys instead of password authentication. [How to use ssh keys.](https://debian-administration.org/article/530/SSH_with_authentication_key_instead_of_password)

Last but not least, run the script simultaneously on both nodes.

```
# On the first node
TF_CONFIG='{"cluster": {"worker": ["10.1.10.58:12345", "10.1.10.250:12345"]}, "task": {"index": 0, "type": "worker"}}' python worker.py

# On the second node
TF_CONFIG='{"cluster": {"worker": ["10.1.10.58:12345", "10.1.10.250:12345"]}, "task": {"index": 1, "type": "worker"}}' python worker.py
```

The training is now distributed across multiple nodes. The output of the two nodes are synchronized since the ```Mirrored``` strategy is used.

###  Run on localhost
```
# On the first node
CUDA_VISIBLE_DEVICES=0 TF_CONFIG='{"cluster": {"worker": ["127.0.0.1:12345", "127.0.0.1:12346"]}, "task": {"index": 0, "type": "worker"}}' python worker.py

# On the second node
CUDA_VISIBLE_DEVICES=1 TF_CONFIG='{"cluster": {"worker": ["127.0.0.1:12345", "127.0.0.1:12346"]}, "task": {"index": 1, "type": "worker"}}' python worker.py
```

## Summary

This tutorial explains how to do distributed training in TensorFlow 2. The key is to set up the ```TF_CONFIG``` environment variable and use the ```MultiWorkerMirroredStrategy``` to scope the model definition.

In this tutorial, we need to run the training script manually on each node with custimized ```TF_CONFIG```. One can see that setting the environment variable quickly become tedious when the number of nodes increases. There are more advanced ways to deploy a distributed training job across a large number of nodes, for example, Horovod, Kubernetes with TF-flow, OpenMPI, or using deployment scripts like Ansible. We will have another tutorial dedicated to that topic.

To reproduce results in this tutorial, please refer to this [TensorFlow 2 distributed training tutorial github repository](https://github.com/lambdal/TensorFlow2-tutorial/tree/master/05-distributed-training).


# print log

* https://www.quora.com/Is-a-mutex-lock-valid-across-processes-or-only-within-threads-of-a-process


# Limitation


Server 0:
```
(hm) wxf@seir19:~/tf2/tensorflow/experiments/distributed_examples_tf2/05-distributed-training$ CUDA_VISIBLE_DEVICES=0 TF_CONFIG='{"cluster": {"worker": ["127.0.0.1:12345", "127.0.0.1:12346"]}, "task": {"index": 0, "type": "worker"}}' python worker.py
2022-01-04 14:09:52.328004: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-01-04 14:09:53.000135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1531] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30990 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2022-01-04 14:09:53.020713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1531] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30990 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0
2022-01-04 14:09:53.037564: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:314] Initialize GrpcChannelCache for job worker -> {0 -> 127.0.0.1:12345, 1 -> 127.0.0.1:12346}
2022-01-04 14:09:53.046606: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:451] Started server with target: grpc://127.0.0.1:12345
2022-01-04 14:10:08.888910: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_UINT8
      type: DT_UINT8
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 50000
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\024TensorSliceDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 32
        }
        dim {
          size: 32
        }
        dim {
          size: 3
        }
      }
      shape {
        dim {
          size: 1
        }
      }
    }
  }
}

Epoch 1/60
2022-01-04 14:10:33.049093: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 7605
195/195 [==============================] - 41s 81ms/step - loss: 3.1325 - sparse_categorical_accuracy: 0.1902
Epoch 2/60
195/195 [==============================] - 21s 80ms/step - loss: 2.4010 - sparse_categorical_accuracy: 0.3981
Epoch 3/60
195/195 [==============================] - 20s 80ms/step - loss: 2.0239 - sparse_categorical_accuracy: 0.5169
Epoch 4/60
195/195 [==============================] - 21s 82ms/step - loss: 1.7094 - sparse_categorical_accuracy: 0.6101
Epoch 5/60
 89/195 [============>.................] - ETA: 8s - loss: 1.5003 - spar  90/195 [============>.................] - ETA: 8s - loss: 1.4985 - spar  91/195 [=============>................] - ETA: 8s - loss: 1.4979 - spar  92/195 [=============>................] - ETA: 8s - loss: 1.4982 - spar  93/195 [=============>................] - ETA: 8s - loss: 1.4974 - spar  94/195 [=============>................] - ETA: 8s - loss: 1.4961 - spar  95/195 [=============>................] - ETA: 8s - loss: 1.4954 - spar  96/195 [=============>................] - ETA: 8s - loss: 1.4938 - spar  97/195 [=============>................] - ETA: 8s - loss: 1.4960 - spar  98/195 [==============>...............] - ETA: 8s - loss: 1.4969 - spar  99/195 [==============>...............] - ETA: 7s - loss: 1.4960 - spar 100/195 [==============>...............] - ETA: 7s - loss: 1.4947 - spar 101/195 [==============>...............] - ETA: 7s - loss: 1.4941 - spar 102/195 [==============>...............] - ETA: 7s - loss: 1.4943 - spar 103/195 [==============>...............] - ETA: 7s - loss: 1.4940 - spar 104/195 [===============>..............] - ETA: 7s - loss: 1.4941 - spar 105/195 [===============>..............] - ETA: 7s - loss: 1.4944 - spar 106/195 [===============>..............] - ETA: 7s - loss: 1.4933 - spar 107/195 [===============>..............] - ETA: 7s - loss: 1.4925 - spar 108/195 [===============>..............] - ETA: 7s - loss: 1.4917 - spar 109/195 [===============>..............] - ETA: 7s - loss: 1.4911 - spar 110/195 [===============>..............] - ETA: 7s - loss: 1.4905 - spar 111/195 [================>.............] - ETA: 6s - loss: 1.4908 - spar 112/195 [================>.............] - ETA: 6s - loss: 1.4904 - spar 113/195 [================>.............] - ETA: 6s - loss: 1.4898 - spar 114/195 [================>.............] - ETA: 6s - loss: 1.4892 - spar 115/195 [================>.............] - ETA: 6s - loss: 1.4896 - spars116/195 [================>.............] - ETA: 6s - loss: 1.4895 - spars117/195 [=================>............] - ETA: 6s - loss: 1.4890 - spars118/195 [=================>............] - ETA: 6s - loss: 1.4870 - spars119/195 [=================>............] - ETA: 6s - loss: 1.4866 - spars120/195 [=================>............] - ETA: 6s - loss: 1.4860 - spars121/195 [=================>............] - ETA: 6s - loss: 1.4860 - spars122/195 [=================>............] - ETA: 6s - loss: 1.4850 - spars123/195 [=================>............] - ETA: 5s - loss: 1.4846 - spars124/195 [==================>...........] - ETA: 5s - loss: 1.4834 - spars125/195 [==================>...........] - ETA: 5s - loss: 1.4834 - spars126/195 [==================>...........] - ETA: 5s - loss: 1.4832 - spars127/195 [==================>...........] - ETA: 5s - loss: 1.4828 - spars128/195 [==================>...........] - ETA: 5s - loss: 1.4823 - spars129/195 [==================>...........] - ETA: 5s - loss: 1.4820 - spars130/195 [===================>..........] - ETA: 5s - loss: 1.4810 - spars131/195 [===================>..........] - ETA: 5s - loss: 1.4808 - spars132/195 [===================>..........] - ETA: 5s - loss: 1.4813 - spars133/195 [===================>..........] - ETA: 5s - loss: 1.4814 - spars134/195 [===================>..........] - ETA: 5s - loss: 1.4813 - spars135/195 [===================>..........] - ETA: 4s - loss: 1.4828 - spars136/195 [===================>..........] - ETA: 4s - loss: 1.4821 - spars137/195 [====================>.........] - ETA: 4s - loss: 1.4812 - spars138/195 [====================>.........] - ETA: 4s - loss: 1.4800 - spars139/195 [====================>.........] - ETA: 4s - loss: 1.4795 - spars140/195 [====================>.........] - ETA: 4s - loss: 1.4785 - spars141/195 [====================>.........] - ETA: 4s - loss: 1.4778 - spars142/195 [====================>.........] - ETA: 4s - loss: 1.4775 - spars143/195 [=====================>........] - ETA: 4s - loss: 1.4776 - spars144/195 [=====================>........] - ETA: 4s - loss: 1.4775 - spars145/195 [=====================>........] - ETA: 4s - loss: 1.4779 - spars146/195 [=====================>........] - ETA: 4s - loss: 1.4773 - spars147/195 [=====================>........] - ETA: 3s - loss: 1.4774 - spars148/195 [=====================>........] - ETA: 3s - loss: 1.4772 - spars149/195 [=====================>........] - ETA: 3s - loss: 1.4772 - spars150/195 [======================>.......] - ETA: 3s - loss: 1.4775 - spars151/195 [======================>.......] - ETA: 3s - loss: 1.4771 - spars152/195 [======================>.......] - ETA: 3s - loss: 1.4770 - spars153/195 [======================>.......] - ETA: 3s - loss: 1.4765 - spars154/195 [======================>.......] - ETA: 3s - loss: 1.4767 - spars155/195 [======================>.......] - ETA: 3s - loss: 1.4766 - spars156/195 [=======================>......] - ETA: 3s - loss: 1.4762 - spars157/195 [=======================>......] - ETA: 3s - loss: 1.4765 - spars158/195 [=======================>......] - ETA: 3s - loss: 1.4762 - spars159/195 [=======================>......] - ETA: 2s - loss: 1.4758 - spars160/195 [=======================>......] - ETA: 2s - loss: 1.4762 - spars161/195 [=======================>......] - ETA: 2s - loss: 1.4769 - spars162/195 [=======================>......] - ETA: 2s - loss: 1.4765 - spars163/195 [========================>.....] - ETA: 2s - loss: 1.4756 - spars164/195 [========================>.....] - ETA: 2s - loss: 1.4755 - spars165/195 [========================>.....] - ETA: 2s - loss: 1.4754 - spars166/195 [========================>.....] - ETA: 2s - loss: 1.4747 - spars167/195 [========================>.....] - ETA: 2s - loss: 1.4738 - spars168/195 [========================>.....] - ETA: 2s - loss: 1.4731 - spars169/195 [=========================>....] - ETA: 2s - loss: 1.4724 - spars170/195 [=========================>....] - ETA: 2s - loss: 1.4723 - spars171/195 [=========================>....] - ETA: 1s - loss: 1.4720 - spars172/195 [=========================>....] - ETA: 1s - loss: 1.4706 - spars173/195 [=========================>....] - ETA: 1s - loss: 1.4703 - spars174/195 [=========================>....] - ETA: 1s - loss: 1.4699 - spars175/195 [=========================>....] - ETA: 1s - loss: 1.4690 - spars176/195 [==========================>...] - ETA: 1s - loss: 1.4686 - spars177/195 [==========================>...] - ETA: 1s - loss: 1.4674 - spars178/195 [==========================>...] - ETA: 1s - loss: 1.4671 - spars179/195 [==========================>...] - ETA: 1s - loss: 1.4670 - spars180/195 [==========================>...] - ETA: 1s - loss: 1.4667 - spars181/195 [==========================>...] - ETA: 1s - loss: 1.4674 - spars182/195 [===========================>..] - ETA: 1s - loss: 1.4675 - spars183/195 [===========================>..] - ETA: 0s - loss: 1.4673 - spars184/195 [===========================>..] - ETA: 0s - loss: 1.4674 - spars185/195 [===========================>..] - ETA: 0s - loss: 1.4670 - spars186/195 [===========================>..] - ETA: 0s - loss: 1.4670 - spars187/195 [===========================>..] - ETA: 0s - loss: 1.4665 - spars188/195 [===========================>..] - ETA: 0s - loss: 1.4658 - spars189/195 [============================>.] - ETA: 0s - loss: 1.4658 - spars190/195 [============================>.] - ETA: 0s - loss: 1.4649 - spars191/195 [============================>.] - ETA: 0s - loss: 1.4645 - spars192/195 [============================>.] - ETA: 0s - loss: 1.4644 - spars193/195 [============================>.] - ETA: 0s - loss: 1.4638 - spars194/195 [============================>.] - ETA: 0s - loss: 1.4631 - spars195/195 [==============================] - ETA: 0s - loss: 1.4629 - spars195/195 [==============================] - 21s 82ms/step - loss: 1.4629 - sparse_categorical_accuracy: 0.6836
Epoch 6/60
  1/195 [..............................] - ETA: 16:38 - loss: 1.3461 - sp  2/195 [..............................] - ETA: 16s - loss: 1.2765 - spar  3/195 [..............................] - ETA: 16s - loss: 1.2602 - spar  4/195 [..............................] - ETA: 15s - loss: 1.2760 - spar  5/195 [..............................] - ETA: 15s - loss: 1.3027 - spar  6/195 [..............................] - ETA: 15s - loss: 1.3030 - spar  7/195 [>.............................] - ETA: 15s - loss: 1.2958 - spar  8/195 [>.............................] - ETA: 15s - loss: 1.3052 - spar  9/195 [>.............................] - ETA: 15s - loss: 1.3005 - spar 10/195 [>.............................] - ETA: 15s - loss: 1.2926 - spar 11/195 [>.............................] - ETA: 15s - loss: 1.2846 - spar 12/195 [>.............................] - ETA: 15s - loss: 1.2894 - spar 13/195 [=>............................] - ETA: 15s - loss: 1.2970 - spar 14/195 [=>............................] - ETA: 15s - loss: 1.2971 - spar 15/195 [=>............................] - ETA: 15s - loss: 1.2960 - spar 16/195 [=>............................] - ETA: 15s - loss: 1.2910 - spar 17/195 [=>............................] - ETA: 15s - loss: 1.2912 - spar 18/195 [=>............................] - ETA: 15s - loss: 1.2878 - spar 19/195 [=>............................] - ETA: 14s - loss: 1.2914 - spar 20/195 [==>...........................] - ETA: 14s - loss: 1.2931 - spar 21/195 [==>...........................] - ETA: 14s - loss: 1.2948 - spar 22/195 [==>...........................] - ETA: 14s - loss: 1.2915 - spar 23/195 [==>...........................] - ETA: 14s - loss: 1.2952 - spar 24/195 [==>...........................] - ETA: 14s - loss: 1.2965 - spar 25/195 [==>...........................] - ETA: 14s - loss: 1.2968 - spar 26/195 [===>..........................] - ETA: 14s - loss: 1.2962 - spar 27/195 [===>..........................] - ETA: 14s - loss: 1.2981 - spar 28/195 [===>..........................] - ETA: 14s - loss: 1.3000 - spar 29/195 [===>..........................] - ETA: 14s - loss: 1.2981 - spar 30/195 [===>..........................] - ETA: 14s - loss: 1.2988 - spar 31/195 [===>..........................] - ETA: 13s - loss: 1.3008 - spar 32/195 [===>..........................] - ETA: 13s - loss: 1.3037 - spar 33/195 [====>.........................] - ETA: 13s - loss: 1.3038 - spar 34/195 [====>.........................] - ETA: 13s - loss: 1.3038 - spar 35/195 [====>.........................] - ETA: 13s - loss: 1.3018 - spar 36/195 [====>.........................] - ETA: 13s - loss: 1.3029 - spar 37/195 [====>.........................] - ETA: 13s - loss: 1.3034 - spar 38/195 [====>.........................] - ETA: 13s - loss: 1.2993 - spar 39/195 [=====>........................] - ETA: 13s - loss: 1.2978 - spar 40/195 [=====>........................] - ETA: 13s - loss: 1.2937 - spar 41/195 [=====>........................] - ETA: 13s - loss: 1.2940 - spar 42/195 [=====>........................] - ETA: 13s - loss: 1.2913 - spar 43/195 [=====>........................] - ETA: 12s - loss: 1.2885 - spar 44/195 [=====>........................] - ETA: 12s - loss: 1.2899 - spar 45/195 [=====>........................] - ETA: 12s - loss: 1.2898 - spar 46/195 [======>.......................] - ETA: 12s - loss: 1.2896 - spar 47/195 [======>.......................] - ETA: 12s - loss: 1.2888 - spar 48/195 [======>.......................] - ETA: 12s - loss: 1.2890 - spar 49/195 [======>.......................] - ETA: 12s - loss: 1.2877 - spar 50/195 [======>.......................] - ETA: 12s - loss: 1.2853 - spar 51/195 [======>.......................] - ETA: 12s - loss: 1.2824 - spar 52/195 [=======>......................] - ETA: 12s - loss: 1.2860 - spar 53/195 [=======>......................] - ETA: 12s - loss: 1.2879 - spar 54/195 [=======>......................] - ETA: 11s - loss: 1.2876 - spar 55/195 [=======>......................] - ETA: 11s - loss: 1.2887 - spar 56/195 [=======>......................] - ETA: 11s - loss: 1.2877 - spar 57/195 [=======>......................] - ETA: 11s - loss: 1.2881 - spar 58/195 [=======>......................] - ETA: 11s - loss: 1.2885 - spar 59/195 [========>.....................] - ETA: 11s - loss: 1.2892 - spar 60/195 [========>.....................] - ETA: 11s - loss: 1.2891 - spar 61/195 [========>.....................] - ETA: 11s - loss: 1.2877 - spar 62/195 [========>.....................] - ETA: 11s - loss: 1.2896 - spar 63/195 [========>.....................] - ETA: 11s - loss: 1.2927 - spar 64/195 [========>.....................] - ETA: 11s - loss: 1.2922 - spar 65/195 [=========>....................] - ETA: 11s - loss: 1.2928 - spar 66/195 [=========>....................] - ETA: 10s - loss: 1.2932 - spar 67/195 [=========>....................] - ETA: 10s - loss: 1.2925 - spar 68/195 [=========>....................] - ETA: 10s - loss: 1.2935 - spar 69/195 [=========>....................] - ETA: 10s - loss: 1.2937 - spar 70/195 [=========>....................] - ETA: 10s - loss: 1.2926 - spar 71/195 [=========>....................] - ETA: 10s - loss: 1.2929 - spar 72/195 [==========>...................] - ETA: 10s - loss: 1.2917 - spar 73/195 [==========>...................] - ETA: 10s - loss: 1.2909 - spar 74/195 [==========>...................] - ETA: 10s - loss: 1.2899 - spar 75/195 [==========>...................] - ETA: 10s - loss: 1.2902 - spar 76/195 [==========>...................] - ETA: 10s - loss: 1.2921 - spar 77/195 [==========>...................] - ETA: 9s - loss: 1.2929 - spars 78/195 [===========>..................] - ETA: 9s - loss: 1.2933 - spars 79/195 [===========>..................] - ETA: 9s - loss: 1.2929 - spars 80/195 [===========>..................] - ETA: 9s - loss: 1.2915 - spars 81/195 [===========>..................] - ETA: 9s - loss: 1.2916 - spars 82/195 [===========>..................] - ETA: 9s - loss: 1.2920 - spars 83/195 [===========>..................] - ETA: 9s - loss: 1.2912 - spars 84/195 [===========>..................] - ETA: 9s - loss: 1.2908 - spars 85/195 [============>.................] - ETA: 9s - loss: 1.2902 - spars 86/195 [============>.................] - ETA: 9s - loss: 1.2910 - spars 87/195 [============>.................] - ETA: 9s - loss: 1.2916 - spars 88/195 [============>.................] - ETA: 9s - loss: 1.2914 - spars 89/195 [============>.................] - ETA: 8s - loss: 1.2914 - spars 90/195 [============>.................] - ETA: 8s - loss: 1.2905 - spars 91/195 [=============>................] - ETA: 8s - loss: 1.2906 - spars 92/195 [=============>................] - ETA: 8s - loss: 1.2900 - spars 93/195 [=============>................] - ETA: 8s - loss: 1.2894 - spars 94/195 [=============>................] - ETA: 8s - loss: 1.2907 - spars 95/195 [=============>................] - ETA: 8s - loss: 1.2908 - spars 96/195 [=============>................] - ETA: 8s - loss: 1.2918 - spars 97/195 [=============>................] - ETA: 8s - loss: 1.2912 - spars 98/195 [==============>...............] - ETA: 8s - loss: 1.2906 - spars 99/195 [==============>...............] - ETA: 8s - loss: 1.2914 - spars100/195 [==============>...............] - ETA: 7s - loss: 1.2915 - spars101/195 [==============>...............] - ETA: 7s - loss: 1.2916 - spars102/195 [==============>...............] - ETA: 7s - loss: 1.2910 - spars103/195 [==============>...............] - ETA: 7s - loss: 1.2909 - spars104/195 [===============>..............] - ETA: 7s - loss: 1.2907 - spars105/195 [===============>..............] - ETA: 7s - loss: 1.2910 - spars106/195 [===============>..............] - ETA: 7s - loss: 1.2914 - spars107/195 [===============>..............] - ETA: 7s - loss: 1.2915 - spars108/195 [===============>..............] - ETA: 7s - loss: 1.2903 - spars109/195 [===============>..............] - ETA: 7s - loss: 1.2904 - spars110/195 [===============>..............] - ETA: 7s - loss: 1.2915 - spars111/195 [================>.............] - ETA: 7s - loss: 1.2917 - spars112/195 [================>.............] - ETA: 6s - loss: 1.2911 - spars113/195 [================>.............] - ETA: 6s - loss: 1.2896 - spars114/195 [================>.............] - ETA: 6s - loss: 1.2895 - spars115/195 [================>.............] - ETA: 6s - loss: 1.2887 - spars116/195 [================>.............] - ETA: 6s - loss: 1.2887 - spars117/195 [=================>............] - ETA: 6s - loss: 1.2879 - spars118/195 [=================>............] - ETA: 6s - loss: 1.2878 - spars119/195 [=================>............] - ETA: 6s - loss: 1.2876 - spars120/195 [=================>............] - ETA: 6s - loss: 1.2866 - spars121/195 [=================>............] - ETA: 6s - loss: 1.2860 - spars122/195 [=================>............] - ETA: 6s - loss: 1.2866 - spars123/195 [=================>............] - ETA: 5s - loss: 1.2857 - spars124/195 [==================>...........] - ETA: 5s - loss: 1.2854 - spars125/195 [==================>...........] - ETA: 5s - loss: 1.2855 - spars126/195 [==================>...........] - ETA: 5s - loss: 1.2849 - spars127/195 [==================>...........] - ETA: 5s - loss: 1.2848 - spars128/195 [==================>...........] - ETA: 5s - loss: 1.2847 - spars129/195 [==================>...........] - ETA: 5s - loss: 1.2842 - spars130/195 [===================>..........] - ETA: 5s - loss: 1.2839 - spars131/195 [===================>..........] - ETA: 5s - loss: 1.2837 - spars132/195 [===================>..........] - ETA: 5s - loss: 1.2839 - spars133/195 [===================>..........] - ETA: 5s - loss: 1.2830 - spars134/195 [===================>..........] - ETA: 5s - loss: 1.2829 - spars135/195 [===================>..........] - ETA: 5s - loss: 1.2824 - spars136/195 [===================>..........] - ETA: 4s - loss: 1.2824 - spars137/195 [====================>.........] - ETA: 4s - loss: 1.2818 - spars138/195 [====================>.........] - ETA: 4s - loss: 1.2808 - spars139/195 [====================>.........] - ETA: 4s - loss: 1.2798 - spars140/195 [====================>.........] - ETA: 4s - loss: 1.2800 - spars141/195 [====================>.........] - ETA: 4s - loss: 1.2797 - spars142/195 [====================>.........] - ETA: 4s - loss: 1.2793 - spars143/195 [=====================>........] - ETA: 4s - loss: 1.2791 - spars144/195 [=====================>........] - ETA: 4s - loss: 1.2795 - spars145/195 [=====================>........] - ETA: 4s - loss: 1.2787 - spars146/195 [=====================>........] - ETA: 4s - loss: 1.2791 - spars147/195 [=====================>........] - ETA: 4s - loss: 1.2786 - spars148/195 [=====================>........] - ETA: 3s - loss: 1.2788 - spars149/195 [=====================>........] - ETA: 3s - loss: 1.2786 - spars150/195 [======================>.......] - ETA: 3s - loss: 1.2784 - spars151/195 [======================>.......] - ETA: 3s - loss: 1.2785 - spars152/195 [======================>.......] - ETA: 3s - loss: 1.2782 - spars153/195 [======================>.......] - ETA: 3s - loss: 1.2777 - spars154/195 [======================>.......] - ETA: 3s - loss: 1.2776 - spars155/195 [======================>.......] - ETA: 3s - loss: 1.2776 - spars156/195 [=======================>......] - ETA: 3s - loss: 1.2772 - spars157/195 [=======================>......] - ETA: 3s - loss: 1.2775 - spars158/195 [=======================>......] - ETA: 3s - loss: 1.2776 - spars159/195 [=======================>......] - ETA: 3s - loss: 1.2783 - spars160/195 [=======================>......] - ETA: 2s - loss: 1.2782 - spars161/195 [=======================>......] - ETA: 2s - loss: 1.2778 - spars162/195 [=======================>......] - ETA: 2s - loss: 1.2771 - spars163/195 [========================>.....] - ETA: 2s - loss: 1.2772 - spars164/195 [========================>.....] - ETA: 2s - loss: 1.2771 - spars165/195 [========================>.....] - ETA: 2s - loss: 1.2771 - spars166/195 [========================>.....] - ETA: 2s - loss: 1.2770 - spars167/195 [========================>.....] - ETA: 2s - loss: 1.2763 - spars168/195 [========================>.....] - ETA: 2s - loss: 1.2758 - spars169/195 [=========================>....] - ETA: 2s - loss: 1.2760 - spars170/195 [=========================>....] - ETA: 2s - loss: 1.2757 - spars171/195 [=========================>....] - ETA: 2s - loss: 1.2758 - spars172/195 [=========================>....] - ETA: 1s - loss: 1.2756 - spars173/195 [=========================>....] - ETA: 1s - loss: 1.2756 - spars174/195 [=========================>....] - ETA: 1s - loss: 1.2749 - spars175/195 [=========================>....] - ETA: 1s - loss: 1.2748 - spars176/195 [==========================>...] - ETA: 1s - loss: 1.2746 - spars177/195 [==========================>...] - ETA: 1s - loss: 1.2743 - spars178/195 [==========================>...] - ETA: 1s - loss: 1.2744 - spars179/195 [==========================>...] - ETA: 1s - loss: 1.2739 - spars180/195 [==========================>...] - ETA: 1s - loss: 1.2736 - spars181/195 [==========================>...] - ETA: 1s - loss: 1.2737 - spars182/195 [===========================>..] - ETA: 1s - loss: 1.2744 - spars183/195 [===========================>..] - ETA: 1s - loss: 1.2734 - spars184/195 [===========================>..] - ETA: 0s - loss: 1.2726 - spars185/195 [===========================>..] - ETA: 0s - loss: 1.2728 - spars186/195 [===========================>..] - ETA: 0s - loss: 1.2727 - spars187/195 [===========================>..] - ETA: 0s - loss: 1.2729 - spars188/195 [===========================>..] - ETA: 0s - loss: 1.2727 - spars189/195 [============================>.] - ETA: 0s - loss: 1.2723 - spars190/195 [============================>.] - ETA: 0s - loss: 1.2715 - spars191/195 [============================>.] - ETA: 0s - loss: 1.2713 - spars192/195 [============================>.] - ETA: 0s - loss: 1.2706 - spars193/195 [============================>.] - ETA: 0s - loss: 1.2704 - spars194/195 [============================>.] - ETA: 0s - loss: 1.2703 - spars195/195 [==============================] - ETA: 0s - loss: 1.2705 - spars195/195 [==============================] - 21s 84ms/step - loss: 1.2705 - sparse_categorical_accuracy: 0.7365
Epoch 7/60
  1/195 [..............................] - ETA: 17:37 - loss: 1.0963 - sp                                    2/195 [..............................] - ETA: 16s - loss: 1.1284 - spar                                    3/195 [..............................] - ETA: 15s - loss: 1.1385 - spar                                    4/195 [..............................] - ETA: 16s - loss: 1.1350 - spar                                    5/195 [..............................] - ETA: 16s - loss: 1.1299 - spar                                    6/195 [..............................] - ETA: 15s - loss: 1.1338 - spar                                    7/195 [>.............................] - ETA: 15s - loss: 1.1283 - spar                                    8/195 [>.............................] - ETA: 15s - loss: 1.1280 - spar                                    9/195 [>.............................] - ETA: 15s - loss: 1.1292 - spar                                   10/195 [>.............................] - ETA: 15s - loss: 1.1297 - spar                                   11/195 [>.............................] - ETA: 15s - loss: 1.1269 - spar                                   12/195 [>.............................] - ETA: 15s - loss: 1.1322 - spar                                   13/195 [=>............................] - ETA: 15s - loss: 1.1312 - spar                                   14/195 [=>............................] - ETA: 14s - loss: 1.1269 - spar                              15/195 [=>............................] - ETA: 14s - loss: 1.1297 - spar                        16/195 [=>............................] - ETA: 14s - loss: 1.1318 - spar                  17/195 [=>............................] - ETA: 14s - loss: 1.1254 - spar            18/195 [=>............................] - ETA: 14s - loss: 1.1208 - spar      19/195 [=>............................] - ETA: 14s - loss: 1.1154 - spar                                   20/195 [==>...........................] - ETA: 14s - loss: 1.1180 - spar                                   21/195 [==>...........................] - ETA: 14s - loss: 1.1154 - spar                                   22/195 [==>...........................] - ETA: 14s - loss: 1.1204 - spar                                   23/195 [==>...........................] - ETA: 14s - loss: 1.1240 - spar                                   24/195 [==>...........................] - ETA: 14s - loss: 1.1257 - spar                                   25/195 [==>...........................] - ETA: 14s - loss: 1.1246 - spar                                   26/195 [===>..........................] - ETA: 14s - loss: 1.1261 - spar                                   27/195 [===>..........................] - ETA: 14s - loss: 1.1264 - spar                                   28/195 [===>..........................] - ETA: 14s - loss: 1.1232 - spar                                   29/195 [===>..........................] - ETA: 14s - loss: 1.1271 - spar                                   30/195 [===>..........................] - ETA: 13s - loss: 1.1283 - spar                                   31/195 [===>..........................] - ETA: 13s - loss: 1.1324 - spar                                   32/195 [===>..........................] - ETA: 13s - loss: 1.1330 - spar                                   33/195 [====>.........................] - ETA: 13s - loss: 1.1342 - spar                             34/195 [====>.........................] - ETA: 13s - loss: 1.1340 - spar                       35/195 [====>.........................] - ETA: 13s - loss: 1.1344 - spar                 36/195 [====>.........................] - ETA: 13s - loss: 1.1345 - spar           37/195 [====>.........................] - ETA: 13s - loss: 1.1366 - spar     38/195 [====>.........................] - ETA: 13s - loss: 1.1372 - spar                                   39/195 [=====>........................] - ETA: 13s - loss: 1.1362 - spar                                   40/195 [=====>........................] - ETA: 13s - loss: 1.1354 - spar                                   41/195 [=====>........................] - ETA: 13s - loss: 1.1348 - spar                                   42/195 [=====>........................] - ETA: 12s - loss: 1.1356 - spar                                   43/195 [=====>........................] - ETA: 12s - loss: 1.1356 - spar                                   44/195 [=====>........................] - ETA: 12s - loss: 1.1372 - spar                                   45/195 [=====>........................] - ETA: 12s - loss: 1.1386 - spar                                   46/195 [======>.......................] - ETA: 12s - loss: 1.1374 - spar                                   47/195 [======>.......................] - ETA: 12s - loss: 1.1388 - spar                                   48/195 [======>.......................] - ETA: 12s - loss: 1.1380 - spar                                   49/195 [======>.......................] - ETA: 12s - loss: 1.1380 - spar                                   50/195 [======>.......................] - ETA: 12s - loss: 1.1388 - spar                                   51/195 [======>.......................] - ETA: 12s - loss: 1.1377 - spar                                  52/195 [=======>......................] - ETA: 11s - loss: 1.1359 - spar                            53/195 [=======>......................] - ETA: 11s - loss: 1.1362 - spar                      54/195 [=======>......................] - ETA: 11s - loss: 1.1360 - spar                55/195 [=======>......................] - ETA: 11s - loss: 1.1365 - spar          56/195 [=======>......................] - ETA: 11s - loss: 1.1379 - spar    57/195 [=======>......................] - ETA: 11s - loss: 1.1383 - spar                                   58/195 [=======>......................] - ETA: 11s - loss: 1.1398 - spar                                   59/195 [========>.....................] - ETA: 11s - loss: 1.1380 - spar                                   60/195 [========>.....................] - ETA: 11s - loss: 1.1391 - spar                                   61/195 [========>.....................] - ETA: 11s - loss: 1.1375 - spar                                   62/195 [========>.....................] - ETA: 11s - loss: 1.1375 - spar                                   63/195 [========>.....................] - ETA: 11s - loss: 1.1380 - spar                                   64/195 [========>.....................] - ETA: 11s - loss: 1.1385 - spar                                   65/195 [=========>....................] - ETA: 10s - loss: 1.1385 - spar                                   66/195 [=========>....................] - ETA: 10s - loss: 1.1371 - spar                                   67/195 [=========>....................] - ETA: 10s - loss: 1.1389 - spar                                   68/195 [=========>....................] - ETA: 10s - loss: 1.1386 - spar                                   69/195 [=========>....................] - ETA: 10s - loss: 1.1387 - spar                                   70/195 [=========>....................] - ETA: 10s - loss: 1.1402 - spar                                 71/195 [=========>....................] - ETA: 10s - loss: 1.1406 - spar                           72/195 [==========>...................] - ETA: 10s - loss: 1.1406 - spar                     73/195 [==========>...................] - ETA: 10s - loss: 1.1408 - spar               74/195 [==========>...................] - ETA: 10s - loss: 1.1414 - spar         75/195 [==========>...................] - ETA: 10s - loss: 1.1400 - spar   76/195 [==========>...................] - ETA: 10s - loss: 1.1392 - spar                                   77/195 [==========>...................] - ETA: 9s - loss: 1.1394 - spars                                   78/195 [===========>..................] - ETA: 9s - loss: 1.1387 - spars                                   79/195 [===========>..................] - ETA: 9s - loss: 1.1386 - spars                                   80/195 [===========>..................] - ETA: 9s - loss: 1.1383 - spars                                   81/195 [===========>..................] - ETA: 9s - loss: 1.1389 - spars                                   82/195 [===========>..................] - ETA: 9s - loss: 1.1384 - spars                                   83/195 [===========>..................] - ETA: 9s - loss: 1.1398 - spars                                   84/195 [===========>..................] - ETA: 9s - loss: 1.1400 - spars                                   85/195 [============>.................] - ETA: 9s - loss: 1.1402 - spars                                   86/195 [============>.................] - ETA: 9s - loss: 1.1401 - spars                                   87/195 [============>.................] - ETA: 9s - loss: 1.1392 - spars                                   88/195 [============>.................] - ETA: 9s - loss: 1.1393 - spars                                   89/195 [============>.................] - ETA: 8s - loss: 1.1384 - spars                                90/195 [============>.................] - ETA: 8s - loss: 1.1388 - spars                          91/195 [=============>................] - ETA: 8s - loss: 1.1387 - spars                    92/195 [=============>................] - ETA: 8s - loss: 1.1389 - spars              93/195 [=============>................] - ETA: 8s - loss: 1.1399 - spars        94/195 [=============>................] - ETA: 8s - loss: 1.1403 - spars  95/195 [=============>................] - ETA: 8s - loss: 1.1411 - spars                                   96/195 [=============>................] - ETA: 8s - loss: 1.1412 - spars                                   97/195 [=============>................] - ETA: 8s - loss: 1.1415 - spars                                   98/195 [==============>...............] - ETA: 8s - loss: 1.1408 - spars                                   99/195 [==============>...............] - ETA: 8s - loss: 1.1401 - spars                                  100/195 [==============>...............] - ETA: 8s - loss: 1.1394 - spars                                  101/195 [==============>...............] - ETA: 7s - loss: 1.1402 - spars                                  102/195 [==============>...............] - ETA: 7s - loss: 1.1401 - spars                                  103/195 [==============>...............] - ETA: 7s - loss: 1.1410 - spars                                  104/195 [===============>..............] - ETA: 7s - loss: 1.1420 - spars                                  105/195 [===============>..............] - ETA: 7s - loss: 1.1405 - spars                                  106/195 [===============>..............] - ETA: 7s - loss: 1.1410 - spars                                  107/195 [===============>..............] - ETA: 7s - loss: 1.1405 - spars                                  108/195 [===============>..............] - ETA: 7s - loss: 1.1407 - spars                              109/195 [===============>..............] - ETA: 7s - loss: 1.1408 - spars                        110/195 [===============>..............] - ETA: 7s - loss: 1.1410 - spars                  111/195 [================>.............] - ETA: 7s - loss: 1.1417 - spars            112/195 [================>.............] - ETA: 7s - loss: 1.1429 - spars      113/195 [================>.............] - ETA: 6s - loss: 1.1428 - spars114/195 [================>.............] - ETA: 6s - loss: 1.1427 - spars                                  115/195 [================>.............] - ETA: 6s - loss: 1.1426 - spars                                  116/195 [================>.............] - ETA: 6s - loss: 1.1418 - spars                                  117/195 [=================>............] - ETA: 6s - loss: 1.1420 - spars                                  118/195 [=================>............] - ETA: 6s - loss: 1.1436 - spars                                  119/195 [=================>............] - ETA: 6s - loss: 1.1435 - spars                                  120/195 [=================>............] - ETA: 6s - loss: 1.1434 - spars                                  121/195 [=================>............] - ETA: 6s - loss: 1.1436 - spars                                  122/195 [=================>............] - ETA: 6s - loss: 1.1430 - spars                                  123/195 [=================>............] - ETA: 6s - loss: 1.1424 - spars                                  124/195 [==================>...........] - ETA: 6s - loss: 1.1426 - spars                                  125/195 [==================>...........] - ETA: 5s - loss: 1.1426 - spars                                  126/195 [==================>...........] - ETA: 5s - loss: 1.1425 - spars                                  127/195 [==================>...........] - ETA: 5s - loss: 1.1422 - spars                             128/195 [==================>...........] - ETA: 5s - loss: 1.1416 - spars                       129/195 [==================>...........] - ETA: 5s - loss: 1.1410 - spars                 130/195 [===================>..........] - ETA: 5s - loss: 1.1412 - spars           131/195 [===================>..........] - ETA: 5s - loss: 1.1408 - spars     132/195 [===================>..........] - ETA: 5s - loss: 1.1413 - spars                                  133/195 [===================>..........] - ETA: 5s - loss: 1.1416 - spars                                  134/195 [===================>..........] - ETA: 5s - loss: 1.1409 - spars                                  135/195 [===================>..........] - ETA: 5s - loss: 1.1406 - spars                                  167/195 [========================>.....] - ETA: 2s - loss: 1.1381 - sparse_categorical_accuracy: 0.7721WARNING:tensorflow:/job:worker/replica:0/task:1 seems down, retrying 1/3
WARNING:tensorflow:/job:worker/replica:0/task:1 seems down, retrying 2/3
ERROR:tensorflow:Cluster check alive failed, /job:worker/replica:0/task:1 is down, aborting collectives: failed to connect to all addresses
Additional GRPC error information from remote target /job:worker/replica:0/task:1:
:{"created":"@1641334381.251669359","description":"Failed to pick subchannel","file":"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc","file_line":3941,"referenced_errors":[{"created":"@1641334381.249773077","description":"failed to connect to all addresses","file":"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc","file_line":393,"grpc_status":14}]}
2022-01-04 14:13:01.252022: E tensorflow/core/common_runtime/base_collective_executor.cc:249] BaseCollectiveExecutor::StartAbort UNAVAILABLE: cluster check alive failed, /job:worker/replica:0/task:1 is down
2022-01-04 14:13:01.265428: E tensorflow/core/common_runtime/ring_alg.cc:290] Aborting RingReduce with UNAVAILABLE: Collective ops is aborted by: cluster check alive failed, /job:worker/replica:0/task:1 is down
The error could be from a previous operation. Restart your program to reset. [type.googleapis.com/tensorflow.DerivedStatus='']
Traceback (most recent call last):
  File "worker.py", line 86, in <module>
    model.fit(train_dataset,
  File "/home/wxf/anaconda3/envs/hm/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/wxf/anaconda3/envs/hm/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 58, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnavailableError:  Collective ops is aborted by: cluster check alive failed, /job:worker/replica:0/task:1 is down
The error could be from a previous operation. Restart your program to reset.
         [[node CollectiveReduceV2
 (defined at /home/wxf/anaconda3/envs/hm/lib/python3.8/site-packages/keras/engine/training.py:866)
]] [Op:__inference_train_function_36600]

Errors may have originated from an input operation.
Input Source operations connected to node CollectiveReduceV2:
In[0] concat/concat:
In[1] CollectiveReduceV2/group_size:
In[2] CollectiveReduceV2/group_key:
In[3] Placeholder:

Operation defined at: (most recent call last)
>>>   File "worker.py", line 86, in <module>
>>>     model.fit(train_dataset,
>>> 
>>>   File "/home/wxf/anaconda3/envs/hm/lib/python3.8/site-packages/keras/utils/traceback_utils.py", line 64, in error_handler
>>>     return fn(*args, **kwargs)
>>> 
>>>   File "/home/wxf/anaconda3/envs/hm/lib/python3.8/site-packages/keras/engine/training.py", line 1216, in fit
>>>     tmp_logs = self.train_function(iterator)
>>> 
>>>   File "/home/wxf/anaconda3/envs/hm/lib/python3.8/site-packages/keras/engine/training.py", line 878, in train_function
>>>     return step_function(self, iterator)
>>> 
>>>   File "/home/wxf/anaconda3/envs/hm/lib/python3.8/site-packages/keras/engine/training.py", line 866, in step_function
>>>     data = next(iterator)
>>> 
(hm) wxf@seir19:~/tf2/tensorflow/experiments/distributed_examples_tf2/05-distributed-training$
```


Server 1:

Shutdown and restart again:

```
(hm) wxf@seir19:~/tf2/tensorflow/experiments/distributed_examples_tf2/05-distributed-training$ CUDA_VISIBLE_DEVICES=1 TF_CONFIG='{"cluster": {"worker": ["127.0.0.1:12345", "127.0.0.1:12346"]}, "task": {"index": 1, "type": "worker"}}' python worker.py
2022-01-04 14:13:05.689922: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-01-04 14:13:06.361080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1531] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30990 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0
2022-01-04 14:13:06.370996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1531] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30990 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0
2022-01-04 14:13:06.382452: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:314] Initialize GrpcChannelCache for job worker -> {0 -> 127.0.0.1:12345, 1 -> 127.0.0.1:12346}
2022-01-04 14:13:06.389144: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:451] Started server with target: grpc://127.0.0.1:12346


```